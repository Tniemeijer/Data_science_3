{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the Tutorial tutorial_cluster_scanpy_object and the tutorial_Clustering_Methods\n",
    "\n",
    "Write a brief summary about the following:\n",
    "\n",
    "-\tWhat are common preprocessing steps? Explain for each step why and when you should execute this step and when not.\n",
    "-\tWhat visualization methods are used in the cluster methods tutorial? Explain why the selected method is the most appropriate method for the visualization. Bonus points: do this as well for the scanpy tutorial.\n",
    "-\tWhat performance/evaluation metrics are in the cluster methods tutorial? Explain why the used methods are the most appropriate method for the evaluation.\n",
    "\n",
    "\n",
    "Bonus:\n",
    "You practice the steps yourself with the breast_cancer dataset (clustering_data.csv)\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Examining the dataset for missing values, and replacing these.\n",
    "\n",
    "   Identifying extra steps to complete the dataset (for instance metadata from another file).\n",
    "\n",
    "   Descriptive statistics, and identifiying outliers. \n",
    "\n",
    "   optional: Transforming the data (Tidy-ing up).\n",
    "\n",
    "   Checking the distribution of the data, skewedness.\n",
    "\n",
    "   Data standardisation -> all kinds of data into data with a mean of 0 and stdev of 1 \n",
    "\n",
    "   Data normalisation -> scales data to a specific range, min- max.\n",
    "   \n",
    "2. for K-means an inertia/ elbow plot: \n",
    " where one looks for the most drastic decreased in inertia to determine the best fitted amount of clusters. This may be helpfull to either check if the assumed amount of clusters also checks out using the clustering. Or to select an amount when no categories are known. \n",
    " In the case of the wine dataset, unbiased I would say that there are around four clusters reading the elbow plot.\n",
    "The dendogram fits the agglomerative clustering well as a visualizing tool. The techinque starts at the bottom with clusters based on an embedding, and continues to 'attach' clusters into a new one to become the new cluster untill all is connected in a single one. This exact process is shown in the dendogram. \n",
    "\n",
    "Scanpy:\n",
    "The clusters are found using Louvain clustering method, the samples are then separated with Uniform Manifold Approximation and Projection (UMAP) with the colouring based on the clusters.\n",
    " \n",
    "\n",
    "\n",
    "3. For evaluating the use of Kmeans, it is used as a feature in the RandomForestClassifier.\n",
    "However in the outcome, the average Area Under the curve and Receiver Operator Characteristic scores (AUC, ROC) of the example with the Kmeans feature added performs a bit worse than the one without. In contrast to the comments in the notebook.\n",
    "\n",
    "In the last part different cluster sizes are tried in a logistic regression estimator.\n",
    "It shows that for some cluster sizes it performs better than others. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
